{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-10-18T10:46:04.202962Z",
     "iopub.status.busy": "2021-10-18T10:46:04.202519Z",
     "iopub.status.idle": "2021-10-18T10:46:13.5801Z",
     "shell.execute_reply": "2021-10-18T10:46:13.57931Z",
     "shell.execute_reply.started": "2021-10-18T10:46:04.202871Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Sentence #       Word  POS    Tag\n",
      "1048565  Sentence: 47958     impact   NN      O\n",
      "1048566  Sentence: 47958          .    .      O\n",
      "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
      "1048568  Sentence: 47959     forces  NNS      O\n",
      "1048569  Sentence: 47959       said  VBD      O\n",
      "1048570  Sentence: 47959       they  PRP      O\n",
      "1048571  Sentence: 47959  responded  VBD      O\n",
      "1048572  Sentence: 47959         to   TO      O\n",
      "1048573  Sentence: 47959        the   DT      O\n",
      "1048574  Sentence: 47959     attack   NN      O\n",
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n",
      "['Iranian', 'officials', 'say', 'they', 'expect', 'to', 'get', 'access', 'to', 'sealed', 'sensitive', 'parts', 'of', 'the', 'plant', 'Wednesday', ',', 'after', 'an', 'IAEA', 'surveillance', 'system', 'begins', 'functioning', '.', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__']\n",
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  1  1  1  2  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Input\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
    "\n",
    "class SentenceGetter(object):\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../input/ner-dataset/ner_datasetreference.csv\", encoding=\"latin1\")\n",
    "data = data.fillna(method=\"ffill\")\n",
    "print(data.tail(10))\n",
    "\n",
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words)\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags)\n",
    "getter = SentenceGetter(data)\n",
    "sent = getter.get_next()\n",
    "print(sent)\n",
    "sentences = getter.sentences\n",
    "max_len = 50\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "X = [[w[0] for w in s] for s in sentences]\n",
    "new_X = []\n",
    "for seq in X:\n",
    "    new_seq = []\n",
    "    for i in range(max_len):\n",
    "        try:\n",
    "            new_seq.append(seq[i])\n",
    "        except:\n",
    "            new_seq.append(\"__PAD__\")\n",
    "    new_X.append(new_seq)\n",
    "X = new_X\n",
    "print(X[1])\n",
    "\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "print(y[1])\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1, random_state=2018)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-10-18T10:46:23.336882Z",
     "iopub.status.busy": "2021-10-18T10:46:23.336603Z",
     "iopub.status.idle": "2021-10-18T10:46:46.601537Z",
     "shell.execute_reply": "2021-10-18T10:46:46.600702Z",
     "shell.execute_reply.started": "2021-10-18T10:46:23.336831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/elmo/2: 250.35MB\n",
      "INFO:tensorflow:Downloaded https://tfhub.dev/google/elmo/2, Total size: 357.40MB\n",
      "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T10:48:06.521612Z",
     "iopub.status.busy": "2021-10-18T10:48:06.521308Z",
     "iopub.status.idle": "2021-10-18T10:48:16.861666Z",
     "shell.execute_reply": "2021-10-18T10:48:16.860929Z",
     "shell.execute_reply.started": "2021-10-18T10:48:06.521542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://www.github.com/keras-team/keras-contrib.git\r\n",
      "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-0smv5nvg\r\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg (from keras-contrib==2.0.8) (2.2.4)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.16.0)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.12.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (3.12)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (2.9.0)\r\n",
      "Requirement already satisfied: keras_applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.0.6)\r\n",
      "Requirement already satisfied: keras_preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.0.5)\r\n",
      "Building wheels for collected packages: keras-contrib\r\n",
      "  Running setup.py bdist_wheel for keras-contrib ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-4tka0z1t/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\r\n",
      "Successfully built keras-contrib\r\n",
      "Installing collected packages: keras-contrib\r\n",
      "Successfully installed keras-contrib-2.0.8\r\n",
      "\u001b[33mYou are using pip version 18.1, however version 21.3 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
    "from keras_contrib.layers import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "c8878f2d2448f257160be3419a4e886e08f4d183",
    "execution": {
     "iopub.execute_input": "2021-10-18T10:49:55.15512Z",
     "iopub.status.busy": "2021-10-18T10:49:55.154836Z",
     "iopub.status.idle": "2021-10-18T10:49:59.632388Z",
     "shell.execute_reply": "2021-10-18T10:49:59.631605Z",
     "shell.execute_reply.started": "2021-10-18T10:49:55.155068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "  warnings.warn('CRF.loss_function is deprecated '\n",
      "/opt/conda/lib/python3.6/site-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n"
     ]
    }
   ],
   "source": [
    "max_len=50\n",
    "n_tags = 18\n",
    "batch_size=32\n",
    "def ElmoEmbedding(x):\n",
    "    return elmo_model(inputs={\n",
    "                            \"tokens\": tf.squeeze(tf.cast(x, 'string')),\n",
    "                            \"sequence_len\": tf.constant(batch_size*[max_len])\n",
    "                      },\n",
    "                      signature=\"tokens\",\n",
    "                      as_dict=True)[\"elmo\"]\n",
    "\n",
    "input_text = Input(shape=(max_len,), dtype='string')\n",
    "embedding = Lambda(ElmoEmbedding, output_shape=(max_len, 1024))(input_text)\n",
    "x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
    "x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                           recurrent_dropout=0.2, dropout=0.2))(x)\n",
    "x = add([x, x_rnn])  # residual connection to the first biLSTM\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)\n",
    "crf = CRF(n_tags)\n",
    "output = crf(out)\n",
    "\n",
    "model = Model(input_text, output)\n",
    "model.compile(optimizer=\"adam\", loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T10:50:04.037712Z",
     "iopub.status.busy": "2021-10-18T10:50:04.037171Z",
     "iopub.status.idle": "2021-10-18T10:50:04.046777Z",
     "shell.execute_reply": "2021-10-18T10:50:04.045739Z",
     "shell.execute_reply.started": "2021-10-18T10:50:04.037659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50, 1024)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 50, 1024)     6295552     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 50, 1024)     6295552     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 50, 1024)     0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 50, 18)       18450       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "crf_1 (CRF)                     (None, 50, 18)       702         time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 12,610,256\n",
      "Trainable params: 12,610,256\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "bb24cfa7f3e0b7bf73785a4b29734d66bdf9461f",
    "execution": {
     "iopub.execute_input": "2021-10-18T10:50:07.859557Z",
     "iopub.status.busy": "2021-10-18T10:50:07.859278Z",
     "iopub.status.idle": "2021-10-18T11:24:47.060831Z",
     "shell.execute_reply": "2021-10-18T11:24:47.059968Z",
     "shell.execute_reply.started": "2021-10-18T10:50:07.859502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38816 samples, validate on 4320 samples\n",
      "Epoch 1/3\n",
      "38816/38816 [==============================] - 800s 21ms/step - loss: 0.0633 - val_loss: 0.0479\n",
      "Epoch 2/3\n",
      "38816/38816 [==============================] - 783s 20ms/step - loss: 0.0406 - val_loss: 0.0409\n",
      "Epoch 3/3\n",
      "38816/38816 [==============================] - 789s 20ms/step - loss: 0.0336 - val_loss: 0.0427\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_text, out)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "X_tr, X_val = X_tr[:1213*batch_size], X_tr[-135*batch_size:]\n",
    "y_tr, y_val = y_tr[:1213*batch_size], y_tr[-135*batch_size:]\n",
    "y_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)\n",
    "y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)\n",
    "\n",
    "history = model.fit(np.array(X_tr), y_tr, validation_data=(np.array(X_val), y_val), \n",
    "                 batch_size=batch_size, epochs=3, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "29b43ea5b5b551288d5e54f8c06a170971d518cb",
    "execution": {
     "iopub.execute_input": "2021-10-18T11:24:48.777017Z",
     "iopub.status.busy": "2021-10-18T11:24:48.776796Z",
     "iopub.status.idle": "2021-10-18T11:24:49.165286Z",
     "shell.execute_reply": "2021-10-18T11:24:49.164441Z",
     "shell.execute_reply.started": "2021-10-18T11:24:48.77697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Pred : (True)\n",
      "==============================\n",
      "Citing         :O     (O)\n",
      "a              :O     (O)\n",
      "draft          :O     (O)\n",
      "report         :O     (O)\n",
      "from           :O     (O)\n",
      "the            :O     (O)\n",
      "U.S.           :B-org (B-org)\n",
      "Government     :I-org (I-org)\n",
      "Accountability :I-org (O)\n",
      "office         :O     (O)\n",
      ",              :O     (O)\n",
      "The            :B-org (B-org)\n",
      "New            :I-org (I-org)\n",
      "York           :I-org (I-org)\n",
      "Times          :I-org (I-org)\n",
      "said           :O     (O)\n",
      "Saturday       :B-tim (B-tim)\n",
      "the            :O     (O)\n",
      "losses         :O     (O)\n",
      "amount         :O     (O)\n",
      "to             :O     (O)\n",
      "between        :O     (O)\n",
      "1,00,000       :O     (O)\n",
      "and            :O     (O)\n",
      "3,00,000       :O     (O)\n",
      "barrels        :O     (O)\n",
      "a              :O     (O)\n",
      "day            :O     (O)\n",
      "of             :O     (O)\n",
      "Iraq           :B-geo (B-geo)\n",
      "'s             :O     (O)\n",
      "declared       :O     (O)\n",
      "oil            :O     (O)\n",
      "production     :O     (O)\n",
      "over           :O     (O)\n",
      "the            :O     (O)\n",
      "past           :B-tim (B-tim)\n",
      "four           :I-tim (I-tim)\n",
      "years          :O     (O)\n",
      ".              :O     (O)\n"
     ]
    }
   ],
   "source": [
    "i = 390\n",
    "p = model.predict(np.array(X_te[i:i+batch_size]))[0]\n",
    "p = np.argmax(p, axis=-1)\n",
    "print(\"{:15} {:5}: ({})\".format(\"Word\", \"Pred\", \"True\"))\n",
    "print(\"=\"*30)\n",
    "for w, true, pred in zip(X_te[i], y_te[i], p):\n",
    "    if w != \"__PAD__\":\n",
    "        print(\"{:15}:{:5} ({})\".format(w, tags[pred], tags[true]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "8260b78cf150c8da6e4d8adb8c421a00012ffde2",
    "execution": {
     "iopub.execute_input": "2021-10-18T11:25:56.486741Z",
     "iopub.status.busy": "2021-10-18T11:25:56.486442Z",
     "iopub.status.idle": "2021-10-18T11:25:57.876824Z",
     "shell.execute_reply": "2021-10-18T11:25:57.875941Z",
     "shell.execute_reply.started": "2021-10-18T11:25:56.486689Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('model', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
