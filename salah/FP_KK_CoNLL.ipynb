{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/swardiantara/fp-kk-2021/blob/main/FP_KK_CoNLL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wbbEgbVfDpwb"
   },
   "outputs": [],
   "source": [
    "dataset_path = './dataset/CoNLL2003/train.txt'\n",
    "dataset = []\n",
    "with open(dataset_path) as fp:\n",
    "  sentence = 1\n",
    "  lines = fp.readlines()\n",
    "  for line in lines:\n",
    "    if (not line in [\"\\n\", \"\\r\\n\"]):\n",
    "      line_arr = line.split(' ')\n",
    "      word = line_arr[0]\n",
    "      tag = line_arr[3].strip()\n",
    "      dataset.append([sentence, word, tag])\n",
    "    else:\n",
    "      sentence += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Nb9wJ8eLFRTb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sm2TPTUODpqq"
   },
   "outputs": [],
   "source": [
    "datasetdf = pd.DataFrame(np.array(dataset), columns=[\"sentence #\", \"word\", \"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "kWS-xWNmFONI",
    "outputId": "38644071-ebca-402e-83f3-75dd6bab12cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence #</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-DOCSTART-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>EU</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rejects</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>German</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>call</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204562</th>\n",
       "      <td>14986</td>\n",
       "      <td>three</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204563</th>\n",
       "      <td>14987</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204564</th>\n",
       "      <td>14987</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204565</th>\n",
       "      <td>14987</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204566</th>\n",
       "      <td>14987</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204567 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence #        word     tag\n",
       "0               1  -DOCSTART-       O\n",
       "1               2          EU   B-ORG\n",
       "2               2     rejects       O\n",
       "3               2      German  B-MISC\n",
       "4               2        call       O\n",
       "...           ...         ...     ...\n",
       "204562      14986       three       O\n",
       "204563      14987     Swansea   B-ORG\n",
       "204564      14987           1       O\n",
       "204565      14987     Lincoln   B-ORG\n",
       "204566      14987           2       O\n",
       "\n",
       "[204567 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BMG_MXZGB_0",
    "outputId": "2345936f-cfb0-40be-f14f-d11d0f58f597"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O         170524\n",
       "B-LOC       7140\n",
       "B-PER       6600\n",
       "B-ORG       6321\n",
       "I-PER       4528\n",
       "I-ORG       3704\n",
       "B-MISC      3438\n",
       "I-LOC       1157\n",
       "I-MISC      1155\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetdf['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sYV3xX-KKfig"
   },
   "outputs": [],
   "source": [
    "def computeRatioAwal(dataset):\n",
    "  negative = dataset.apply(lambda x : True if x['tag'] == \"O\" else False, axis = 1)\n",
    "  num_negative = len(negative[negative == True].index)\n",
    "  num_positive = len(negative[negative == False].index)\n",
    "  return num_negative / num_positive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgdLwtrhKhdI",
    "outputId": "fce16857-e176-4418-8ada-276cd7c3979e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0090767558675795\n"
     ]
    }
   ],
   "source": [
    "print(computeRatioAwal(datasetdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566
    },
    "id": "6E0OEAZQF8kB",
    "outputId": "a30dae4e-12d3-4d08-d44e-8cab7de67f93"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize = (16,8))\n",
    "sns.set_style('darkgrid')\n",
    "sns.histplot(datasetdf['tag'])\n",
    "plt.tight_layout(pad=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgD_KfjjGLlO"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "n3J89AdMGMyY"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def get_dict_map(data, token_or_tag):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set(data['word'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['tag'].to_list()))\n",
    "    \n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "    return tok2idx, idx2tok\n",
    "token2idx, idx2token = get_dict_map(datasetdf, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(datasetdf, 'tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUUxmsgkGXdC",
    "outputId": "c8aa2ae5-b712-4de1-9c99-d8a5707cfdb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sward\\.conda\\envs\\Data Mining\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "datasetdf['word_idx'] = datasetdf['word'].map(token2idx)\n",
    "datasetdf['tag_idx'] = datasetdf['tag'].map(tag2idx)\n",
    "datasetdf_fillna = datasetdf.fillna(method='ffill', axis=0)\n",
    "# Groupby and collect columns\n",
    "datasetdf_group = datasetdf_fillna.groupby(\n",
    "['sentence #'],as_index=False\n",
    ")['word', 'tag', 'word_idx', 'tag_idx'].agg(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "ncj_HPedGm-J",
    "outputId": "b2ebfe78-ca90-427e-e367-fd3f57a57851"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence #</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>word_idx</th>\n",
       "      <th>tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[-DOCSTART-]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[16594]</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>[Fischler, proposed, EU-wide, measures, after,...</td>\n",
       "      <td>[B-PER, O, B-MISC, O, O, O, O, B-LOC, O, B-LOC...</td>\n",
       "      <td>[22154, 14097, 21650, 13731, 11829, 22371, 153...</td>\n",
       "      <td>[0, 2, 4, 2, 2, 2, 2, 5, 2, 5, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>[Port, conditions, update, -, Syria, -, Lloyds...</td>\n",
       "      <td>[O, O, O, O, B-LOC, O, B-ORG, I-ORG, O]</td>\n",
       "      <td>[12537, 12247, 13433, 4155, 7810, 4155, 14993,...</td>\n",
       "      <td>[2, 2, 2, 2, 5, 2, 1, 8, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>[-DOCSTART-]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[16594]</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>[*, Reinsurance, group, Scor, gained, 2.1, per...</td>\n",
       "      <td>[O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, B-...</td>\n",
       "      <td>[15067, 5660, 3875, 8676, 12321, 2348, 18708, ...</td>\n",
       "      <td>[2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14982</th>\n",
       "      <td>9995</td>\n",
       "      <td>[Index, heavyweights, Elf, and, Rhone, Poulenc...</td>\n",
       "      <td>[O, O, B-ORG, O, B-ORG, I-ORG, O, O, O, O, O, ...</td>\n",
       "      <td>[14690, 7285, 8910, 15576, 3223, 19087, 13998,...</td>\n",
       "      <td>[2, 2, 1, 2, 1, 8, 2, 2, 2, 2, 2, 2, 5, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>9996</td>\n",
       "      <td>[\", People, are, morose, and, it, 's, not, the...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[18795, 2596, 12767, 7443, 15576, 2330, 4302, ...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14984</th>\n",
       "      <td>9997</td>\n",
       "      <td>[*, UIC, ,, part, of, insurer, GAN, ,, slid, 1...</td>\n",
       "      <td>[O, B-ORG, O, O, O, O, B-ORG, O, O, O, O, O, O...</td>\n",
       "      <td>[15067, 14189, 10806, 17233, 19134, 6342, 1718...</td>\n",
       "      <td>[2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14985</th>\n",
       "      <td>9998</td>\n",
       "      <td>[Markets, were, disappointed, by, a, recapital...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[7624, 9412, 7516, 15020, 22425, 12993, 19134,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14986</th>\n",
       "      <td>9999</td>\n",
       "      <td>[*, Supermarkets, group, Carrefour, gained, 2....</td>\n",
       "      <td>[O, O, O, B-ORG, O, O, O, O, O, O, O, O, B-ORG...</td>\n",
       "      <td>[15067, 3682, 3875, 2924, 12321, 6745, 18708, ...</td>\n",
       "      <td>[2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 8, 8, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14987 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence #                                               word  \\\n",
       "0              1                                       [-DOCSTART-]   \n",
       "1             10  [Fischler, proposed, EU-wide, measures, after,...   \n",
       "2            100  [Port, conditions, update, -, Syria, -, Lloyds...   \n",
       "3           1000                                       [-DOCSTART-]   \n",
       "4          10000  [*, Reinsurance, group, Scor, gained, 2.1, per...   \n",
       "...          ...                                                ...   \n",
       "14982       9995  [Index, heavyweights, Elf, and, Rhone, Poulenc...   \n",
       "14983       9996  [\", People, are, morose, and, it, 's, not, the...   \n",
       "14984       9997  [*, UIC, ,, part, of, insurer, GAN, ,, slid, 1...   \n",
       "14985       9998  [Markets, were, disappointed, by, a, recapital...   \n",
       "14986       9999  [*, Supermarkets, group, Carrefour, gained, 2....   \n",
       "\n",
       "                                                     tag  \\\n",
       "0                                                    [O]   \n",
       "1      [B-PER, O, B-MISC, O, O, O, O, B-LOC, O, B-LOC...   \n",
       "2                [O, O, O, O, B-LOC, O, B-ORG, I-ORG, O]   \n",
       "3                                                    [O]   \n",
       "4      [O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, B-...   \n",
       "...                                                  ...   \n",
       "14982  [O, O, B-ORG, O, B-ORG, I-ORG, O, O, O, O, O, ...   \n",
       "14983  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "14984  [O, B-ORG, O, O, O, O, B-ORG, O, O, O, O, O, O...   \n",
       "14985  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "14986  [O, O, O, B-ORG, O, O, O, O, O, O, O, O, B-ORG...   \n",
       "\n",
       "                                                word_idx  \\\n",
       "0                                                [16594]   \n",
       "1      [22154, 14097, 21650, 13731, 11829, 22371, 153...   \n",
       "2      [12537, 12247, 13433, 4155, 7810, 4155, 14993,...   \n",
       "3                                                [16594]   \n",
       "4      [15067, 5660, 3875, 8676, 12321, 2348, 18708, ...   \n",
       "...                                                  ...   \n",
       "14982  [14690, 7285, 8910, 15576, 3223, 19087, 13998,...   \n",
       "14983  [18795, 2596, 12767, 7443, 15576, 2330, 4302, ...   \n",
       "14984  [15067, 14189, 10806, 17233, 19134, 6342, 1718...   \n",
       "14985  [7624, 9412, 7516, 15020, 22425, 12993, 19134,...   \n",
       "14986  [15067, 3682, 3875, 2924, 12321, 6745, 18708, ...   \n",
       "\n",
       "                                                 tag_idx  \n",
       "0                                                    [2]  \n",
       "1      [0, 2, 4, 2, 2, 2, 2, 5, 2, 5, 2, 2, 2, 2, 2, ...  \n",
       "2                            [2, 2, 2, 2, 5, 2, 1, 8, 2]  \n",
       "3                                                    [2]  \n",
       "4      [2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, ...  \n",
       "...                                                  ...  \n",
       "14982  [2, 2, 1, 2, 1, 8, 2, 2, 2, 2, 2, 2, 5, 2, 2, ...  \n",
       "14983  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "14984  [2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "14985  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "14986  [2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 8, 8, ...  \n",
       "\n",
       "[14987 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetdf_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HvNyldtxG317"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def get_pad_train_test_val(data_group, data):\n",
    "\n",
    "    #get max token and tag length\n",
    "    n_token = len(list(set(data['word'].to_list())))\n",
    "    n_tag = len(list(set(data['tag'].to_list())))\n",
    "\n",
    "    #Pad tokens (X var)    \n",
    "    tokens = data_group['word_idx'].tolist()\n",
    "    maxlen = max([len(s) for s in tokens])\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n",
    "\n",
    "    #Pad Tags (y var) and convert it into one hot encoding\n",
    "    tags = data_group['tag_idx'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n",
    "    n_tags = len(tag2idx)\n",
    "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
    "    \n",
    "    #Split train, test and validation set\n",
    "    tokens_, test_tokens, tags_, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
    "    train_tokens, val_tokens, train_tags, val_tags = train_test_split(tokens_, tags_, test_size = 0.25,train_size =0.75, random_state=2020)\n",
    "\n",
    "    print(\n",
    "        'train_tokens length:', len(train_tokens),\n",
    "        '\\ntrain_tokens length:', len(train_tokens),\n",
    "        '\\ntest_tokens length:', len(test_tokens),\n",
    "        '\\ntest_tags:', len(test_tags),\n",
    "        '\\nval_tokens:', len(val_tokens),\n",
    "        '\\nval_tags:', len(val_tags),\n",
    "    )\n",
    "    \n",
    "    return train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7G2z_689HWQf",
    "outputId": "704efd24-d487-4607-f900-488416c471bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tokens length: 10116 \n",
      "train_tokens length: 10116 \n",
      "test_tokens length: 1499 \n",
      "test_tags: 1499 \n",
      "val_tokens: 3372 \n",
      "val_tags: 3372\n",
      "train_tags:  (10116, 113, 9) val_tags:  (3372, 113, 9) test_tags:  (1499, 113, 9)\n"
     ]
    }
   ],
   "source": [
    "train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags = get_pad_train_test_val(datasetdf_group, datasetdf)\n",
    "train_tags = np.array(train_tags)\n",
    "val_tags = np.array(val_tags)\n",
    "test_tags = np.array(test_tags)\n",
    "print('train_tags: ',train_tags.shape,'val_tags: ',val_tags.shape,'test_tags: ',test_tags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7V-Tb2q4Hgx0",
    "outputId": "db2c2a85-1355-45a6-b77c-ed1e5cae5199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1143108\n",
      "{0: 27.939287285525737, 1: 29.97687042718905, 2: 0.11341764736873594, 3: 157.38785625774474, 4: 54.34830979888746, 5: 25.995088006549324, 6: 40.82674381227901, 7: 157.58312655086849, 8: 50.4616607071911}\n",
      "(10116, 113)\n",
      "(10116, 113)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "train_temp_tags = np.ravel(np.argmax(train_tags, axis=-1))\n",
    "print(len(train_temp_tags))\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight ='balanced', \n",
    "    classes = np.unique(train_temp_tags), \n",
    "    y = train_temp_tags\n",
    "    )\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(class_weight_dict)\n",
    "\n",
    "train_label = np.argmax(train_tags, axis=-1)\n",
    "print(train_tokens.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpJ1psK9H1Vx"
   },
   "source": [
    "Create and Train Model (BiLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YBrTCF2GH4O1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "T0994PYRH9iG"
   },
   "outputs": [],
   "source": [
    "input_dim = len(list(set(datasetdf['word'].to_list())))+1\n",
    "output_dim = 64\n",
    "input_length = max([len(s) for s in datasetdf_group['word_idx'].tolist()])\n",
    "n_tags = len(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "X5MHBXrKIGX6"
   },
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add((Dense(n_tags, activation=\"softmax\")))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUY-cSDsIjh0",
    "outputId": "17a0ce97-7cb4-4af9-ba03-8b7b65f4e558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 27.939287285525737, 1: 29.97687042718905, 2: 28.52779541057316, 3: 157.38785625774474, 4: 54.34830979888746, 5: 25.995088006549324, 6: 40.82674381227901, 7: 157.58312655086849, 8: 50.4616607071911}\n",
      "(10116, 113)\n"
     ]
    }
   ],
   "source": [
    "maj_index = tag2idx['O']\n",
    "\n",
    "''' Change it More for Better Fine-Tuning '''\n",
    "\n",
    "class_weight_dict[maj_index] = 28.5277954105731576 \n",
    "print(class_weight_dict)\n",
    "sample_weights = np.ones(shape=(len(train_label), train_label.shape[-1]))\n",
    "for i in range(17):\n",
    "    sample_weights[train_label == i] = class_weight_dict.get(i)\n",
    "print(sample_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "1kA-dy7gIMFj",
    "outputId": "9f2ab0eb-02a8-4b9a-9ed5-bb58642901f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 113, 64)           1512000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 113, 128)          66048     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 113, 64)           49408     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 113, 9)            585       \n",
      "=================================================================\n",
      "Total params: 1,628,041\n",
      "Trainable params: 1,628,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found a sample_weight array with shape (10116, 113). In order to use timestep-wise sample weights, you should specify sample_weight_mode=\"temporal\" in compile(); found \"None\" instead. If you just mean to use sample-wise weights, make sure your sample_weight array is 1D.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-fb5a54ea5b03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnlp_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_bilstm_lstm_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\Data Mining\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\Data Mining\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Data Mining\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         steps=steps_per_epoch)\n\u001b[0m\u001b[0;32m    553\u001b[0m     (x, y, sample_weights,\n\u001b[0;32m    554\u001b[0m      \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Data Mining\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\.conda\\envs\\Data Mining\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2479\u001b[0m           \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardize_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m           for (ref, sw, cw, mode) in zip(y, sample_weights, class_weights,\n\u001b[1;32m-> 2481\u001b[1;33m                                          feed_sample_weight_modes)\n\u001b[0m\u001b[0;32m   2482\u001b[0m       ]\n\u001b[0;32m   2483\u001b[0m       \u001b[1;31m# Check that all arrays have the same length.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Data Mining\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2478\u001b[0m       sample_weights = [\n\u001b[0;32m   2479\u001b[0m           \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardize_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2480\u001b[1;33m           for (ref, sw, cw, mode) in zip(y, sample_weights, class_weights,\n\u001b[0m\u001b[0;32m   2481\u001b[0m                                          feed_sample_weight_modes)\n\u001b[0;32m   2482\u001b[0m       ]\n",
      "\u001b[1;32m~\\.conda\\envs\\Data Mining\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_weights\u001b[1;34m(y, sample_weight, class_weight, sample_weight_mode)\u001b[0m\n\u001b[0;32m    968\u001b[0m                        \u001b[1;34m'instead. If you just mean to use sample-wise weights, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m                        \u001b[1;34m'make sure your sample_weight array is 1D.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m                        .format(sample_weight.shape, sample_weight_mode))\n\u001b[0m\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found a sample_weight array with shape (10116, 113). In order to use timestep-wise sample weights, you should specify sample_weight_mode=\"temporal\" in compile(); found \"None\" instead. If you just mean to use sample-wise weights, make sure your sample_weight array is 1D."
     ]
    }
   ],
   "source": [
    "nlp_model = get_bilstm_lstm_model()\n",
    "plot_model(nlp_model)\n",
    "his = nlp_model.fit(train_tokens, train_label , batch_size = 64, epochs=5, validation_split=0.2, sample_weight = sample_weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gXPZJ-HiKsdl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.models.save_model(nlp_model, filepath  = \"/content/drive/MyDrive/Colab Notebooks/ner-kk/bilstm_CoNLL_baseline.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3783nJkI2o6"
   },
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPcWcn0AI0a_",
    "outputId": "4a156c5a-3b74-4244-c5ec-32563ffac8f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1499, 113) (1499, 113)\n",
      "47/47 [==============================] - 4s 63ms/step - loss: 0.0403 - accuracy: 0.9868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.040282320231199265, 0.9867699146270752]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/ner-kk/bilstm_CoNLL_baseline.h5')\n",
    "\n",
    "y_test = np.argmax(test_tags, axis=-1)\n",
    "print(test_tokens.shape,y_test.shape)\n",
    "nlp_model.evaluate(test_tokens, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2-ZJrAXaLVnk"
   },
   "outputs": [],
   "source": [
    "def predict(seed):\n",
    "    query  = test_tokens[seed]\n",
    "    query_text = []\n",
    "    for i in query.tolist():\n",
    "        query_text.append(idx2token.get(i))\n",
    "    print('Query_Text: ',' '.join(query_text[:10]))\n",
    "\n",
    "    ans = y_test[seed]\n",
    "    ans_text = []\n",
    "    for i in ans.tolist():\n",
    "        ans_text.append(idx2tag.get(i))\n",
    "    print('Tag_Text: ',' '.join(ans_text[:10]))\n",
    "\n",
    "    query = query.reshape(1,-1)\n",
    "    pred = nlp_model.predict(query)\n",
    "    pred = np.ravel(np.argmax(pred, axis=-1))\n",
    "    print('Query: ',query.shape,'Prediction: ',pred.shape)\n",
    "\n",
    "    pred_list = []\n",
    "    for i in pred.tolist():\n",
    "        pred_list.append(idx2tag.get(i))\n",
    "    print('Prediction_Text: ',' '.join(pred_list[:10])) \n",
    "    print()\n",
    "    print('--- Better-Representation---')\n",
    "    print()\n",
    "    rep_qr = []\n",
    "    for q, r_tag in zip(query_text[:10], ans_text[:10]):\n",
    "        rep_qr.append(q)\n",
    "        rep_qr.append('['+r_tag+']')\n",
    "    print('Actual_NER: ',' '.join(rep_qr),'....')\n",
    "    print()\n",
    "    rep_qp = []\n",
    "    for q, r_tag in zip(query_text[:10], pred_list[:10]):\n",
    "        rep_qp.append(q)\n",
    "        rep_qp.append('['+r_tag+']')\n",
    "    print('--'*70)\n",
    "    print()\n",
    "    print('Predicted_NER: ',' '.join(rep_qp),'....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkfbXlpWLjTe",
    "outputId": "4e9fe37b-43b6-4a70-b854-18d9f3e152c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query_Text:  In 1993 , she fell in Rome and broke three\n",
      "Tag_Text:  O O O O O O B-LOC O O O\n",
      "Query:  (1, 113) Prediction:  (113,)\n",
      "Prediction_Text:  O O O O O O B-PER O O O\n",
      "\n",
      "--- Better-Representation---\n",
      "\n",
      "Actual_NER:  In [O] 1993 [O] , [O] she [O] fell [O] in [O] Rome [B-LOC] and [O] broke [O] three [O] ....\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Predicted_NER:  In [O] 1993 [O] , [O] she [O] fell [O] in [O] Rome [B-PER] and [O] broke [O] three [O] ....\n"
     ]
    }
   ],
   "source": [
    "seed = 11\n",
    "predict(seed)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3JH9Nk398iF3rEdaxQGi2",
   "include_colab_link": true,
   "name": "FP-KK-CoNLL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
