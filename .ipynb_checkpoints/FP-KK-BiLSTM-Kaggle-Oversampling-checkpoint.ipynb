{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/swardiantara/fp-kk-2021/blob/main/FP_KK_NER_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2ulj3IIK5w5"
   },
   "source": [
    "https://www.kaggle.com/alikmondal/named-entity-recognition-using-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7yO08r9ZHN_H"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nn1ouC9EHrRk",
    "outputId": "51dc2af1-34aa-4c29-ad61-8c376b9facb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = './dataset/ner_datasetreference.csv'\n",
    "dataset = pd.read_csv(dataset_path, encoding= 'unicode_escape')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "v4Kl3drKICu4",
    "outputId": "53ef9e46-5f35-471d-fa5c-966061252351"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag  Class\n",
       "0  Sentence: 1      Thousands  NNS   O      0\n",
       "1          NaN             of   IN   O      0\n",
       "2          NaN  demonstrators  NNS   O      0\n",
       "3          NaN           have  VBP   O      0\n",
       "4          NaN        marched  VBN   O      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "v522jNLlw0dn"
   },
   "outputs": [],
   "source": [
    "dataset.drop(['POS', 'Class'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrviKqWUbpAj",
    "outputId": "d8f0e090-a3f2-4dcc-b18a-c8566106337a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        887908\n",
       "B-geo     37644\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "I-per     17251\n",
       "B-per     16990\n",
       "I-org     16784\n",
       "B-gpe     15870\n",
       "I-geo      7414\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Tag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "MaE0b6DQ94_U",
    "outputId": "1cc3d5cb-dd3c-41eb-d193-e904cdc9d65a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word Tag\n",
       "0  Sentence: 1      Thousands   O\n",
       "1          NaN             of   O\n",
       "2          NaN  demonstrators   O\n",
       "3          NaN           have   O\n",
       "4          NaN        marched   O"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566
    },
    "id": "rK2H5sqoIROY",
    "outputId": "6cdf492a-c624-444d-e6cb-de1c9e17d204"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'O'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-305f514f2258>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'darkgrid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Data Mining\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36mdistplot\u001b[1;34m(a, bins, hist, kde, rug, fit, hist_kws, kde_kws, rug_kws, fit_kws, color, vertical, norm_hist, axlabel, label, ax)\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mkws\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"edgecolor\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[0mkws\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"color\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkws\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Data Mining\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Data Mining\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    795\u001b[0m               dtype='datetime64[ns]')\n\u001b[0;32m    796\u001b[0m         \"\"\"\n\u001b[1;32m--> 797\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Data Mining\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Data Mining\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Data Mining\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'O'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize = (16,8))\n",
    "sns.set_style('darkgrid')\n",
    "sns.distplot(dataset['Tag'])\n",
    "plt.tight_layout(pad=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QQQ1H4ijWNAb"
   },
   "outputs": [],
   "source": [
    "def computeRatioAwal(dataset):\n",
    "  negative = dataset.apply(lambda x : True if x['Tag'] == \"O\" else False, axis = 1)\n",
    "  num_negative = len(negative[negative == True].index)\n",
    "  num_positive = len(negative[negative == False].index)\n",
    "  return num_negative / num_positive \n",
    "# Count number of True in the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Zm0JR5AWc4v",
    "outputId": "cff4026a-2c6e-4d4b-85be-f9b8ac6e328f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.526386874716027\n"
     ]
    }
   ],
   "source": [
    "print(computeRatioAwal(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZMJ94c0ggpd_",
    "outputId": "d5988a4a-44df-4136-9e5f-4c5b0ab48619"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sward\\.conda\\envs\\Data Mining\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dataset_fillna = dataset.fillna(method='ffill', axis=0)\n",
    "dataset_group = dataset_fillna.groupby(['Sentence #'], as_index=False)['Word', 'Tag'].agg(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "lO6uvN1Ug1AN",
    "outputId": "37c57113-9e39-4384-e827-d752db3a86a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
       "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47954</th>\n",
       "      <td>Sentence: 9995</td>\n",
       "      <td>[Opposition, leader, Mir, Hossein, Mousavi, ha...</td>\n",
       "      <td>[O, O, O, B-per, I-per, O, O, O, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47955</th>\n",
       "      <td>Sentence: 9996</td>\n",
       "      <td>[On, Thursday, ,, Iranian, state, media, publi...</td>\n",
       "      <td>[O, B-tim, O, B-gpe, O, O, O, O, O, O, O, O, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47956</th>\n",
       "      <td>Sentence: 9997</td>\n",
       "      <td>[Following, Iran, 's, disputed, June, 12, elec...</td>\n",
       "      <td>[O, B-geo, O, O, B-tim, I-tim, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47957</th>\n",
       "      <td>Sentence: 9998</td>\n",
       "      <td>[Since, then, ,, authorities, have, held, publ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47958</th>\n",
       "      <td>Sentence: 9999</td>\n",
       "      <td>[The, United, Nations, is, praising, the, use,...</td>\n",
       "      <td>[O, B-org, I-org, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47959 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence #                                               Word  \\\n",
       "0          Sentence: 1  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1         Sentence: 10  [Iranian, officials, say, they, expect, to, ge...   \n",
       "2        Sentence: 100  [Helicopter, gunships, Saturday, pounded, mili...   \n",
       "3       Sentence: 1000  [They, left, after, a, tense, hour-long, stand...   \n",
       "4      Sentence: 10000  [U.N., relief, coordinator, Jan, Egeland, said...   \n",
       "...                ...                                                ...   \n",
       "47954   Sentence: 9995  [Opposition, leader, Mir, Hossein, Mousavi, ha...   \n",
       "47955   Sentence: 9996  [On, Thursday, ,, Iranian, state, media, publi...   \n",
       "47956   Sentence: 9997  [Following, Iran, 's, disputed, June, 12, elec...   \n",
       "47957   Sentence: 9998  [Since, then, ,, authorities, have, held, publ...   \n",
       "47958   Sentence: 9999  [The, United, Nations, is, praising, the, use,...   \n",
       "\n",
       "                                                     Tag  \n",
       "0      [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...  \n",
       "1      [B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...  \n",
       "2      [O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...  \n",
       "3                      [O, O, O, O, O, O, O, O, O, O, O]  \n",
       "4      [B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...  \n",
       "...                                                  ...  \n",
       "47954  [O, O, O, B-per, I-per, O, O, O, O, O, O, O, O...  \n",
       "47955  [O, B-tim, O, B-gpe, O, O, O, O, O, O, O, O, B...  \n",
       "47956  [O, B-geo, O, O, B-tim, I-tim, O, O, O, O, O, ...  \n",
       "47957  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "47958  [O, B-org, I-org, O, O, O, O, O, O, O, O, O, O...  \n",
       "\n",
       "[47959 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ygghQAwnNKFF"
   },
   "outputs": [],
   "source": [
    "geoList = [\"Eastern\", \"Western\", \"Northern\", \"Southern\"]\n",
    "orgList = [\"Agency\", \"Federation\", \"Community\"]\n",
    "perList = [\"Woods\", \"Pearson\", \"Lee\", \"Mills\", \"Mason\", \"Andrews\", \"Frederick\", \"Christopher\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_zSV96puJvT3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def generateRandomEntity(entityType):\n",
    "  if(entityType == 'GEO'):\n",
    "    return random.choice(geoList)\n",
    "  elif(entityType == 'ORG'):\n",
    "    return random.choice(orgList)\n",
    "  else:\n",
    "    return random.choice(perList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9P3hfyZAFFz2"
   },
   "outputs": [],
   "source": [
    "def nerOversample(dataset):\n",
    "  last = False\n",
    "  for sentence in range(0, dataset.shape[0]):\n",
    "    # if (row == dataset.shape[0] - 1): last = True\n",
    "    # if((dataset.loc[row, 'Tag'] == 'B-geo' and last) or (dataset.loc[row, 'Tag'] == 'B-geo' and dataset.loc[row+1, 'Tag'] == 'O')):\n",
    "    #   dataset.loc[row, 'Tag'] = 'I-geo'\n",
    "    #   dataset.insert(row, [dataset.loc[row, 'Sentence #'], generateRandomEntity('GEO'), 'B-geo'])\n",
    "\n",
    "    # elif((dataset.loc[row, 'Tag'] == 'B-org' and last) or (dataset.loc[row, 'Tag'] == 'B-org' and dataset.loc[row+1, 'Tag'] == 'O')):\n",
    "    #   dataset.insert(row+1, [dataset.loc[row, 'Sentence #'], generateRandomEntity('ORG'), 'I-org'])\n",
    "    # elif((dataset.loc[row, 'Tag'] == 'B-per' and last) or (dataset.loc[row, 'Tag'] == 'B-per' and dataset.loc[row+1, 'Tag'] == 'O')):\n",
    "    #   dataset.insert(row+1, [dataset.loc[row, 'Sentence #'], generateRandomEntity('PER'), 'I-per'])\n",
    "\n",
    "    # sentence = 10002\n",
    "    for tag in range(0, len(dataset.loc[sentence, 'Tag'])):\n",
    "      if (tag == len(dataset.loc[sentence, 'Tag']) - 1): last = True\n",
    "      if((dataset.loc[sentence, 'Tag'][tag] == 'B-geo' and last == True) or (dataset.loc[sentence, 'Tag'][tag] == 'B-geo' and dataset.loc[sentence, 'Tag'][tag+1] == 'O')):\n",
    "        dataset.loc[sentence, 'Tag'][tag] = 'I-geo'\n",
    "        # dataset.loc[sentence, 'Tag_idx'][tag] = tag2idx.get('I-geo')\n",
    "        dataset.loc[sentence, 'Word'].insert(tag, generateRandomEntity('GEO'))\n",
    "        dataset.loc[sentence, 'Tag'].insert(tag, 'B-geo')\n",
    "        # dataset.loc[sentence, 'Tag_idx'].insert(tag, tag2idx.get('B-geo'))\n",
    "      elif((dataset.loc[sentence, 'Tag'][tag] == 'B-org' and last == True) or (dataset.loc[sentence, 'Tag'][tag] == 'B-org' and dataset.loc[sentence, 'Tag'][tag+1] == 'O')):\n",
    "        dataset.loc[sentence, 'Word'].insert(tag+1, generateRandomEntity('ORG'))\n",
    "        dataset.loc[sentence, 'Tag'].insert(tag+1, 'I-org')\n",
    "        # dataset.loc[sentence, 'Tag_idx'].insert(tag+1, tag2idx.get('I-org'))\n",
    "      elif((dataset.loc[sentence, 'Tag'][tag] == 'B-per' and last == True) or (dataset.loc[sentence, 'Tag'][tag] == 'B-per' and dataset.loc[sentence, 'Tag'][tag+1] == 'O')):\n",
    "        dataset.loc[sentence, 'Word'].insert(tag+1, generateRandomEntity('PER'))\n",
    "        dataset.loc[sentence, 'Tag'].insert(tag+1, 'I-per')\n",
    "        # dataset.loc[sentence, 'Tag_idx'].insert(tag+1, tag2idx.get('I-per'))\n",
    "      # print(dataset.loc[sentence, 'Word'][tag], dataset.loc[sentence, 'Tag'][tag], dataset.loc[sentence, 'Tag_idx'][tag])\n",
    "    #update ratio \n",
    "    # dataset.loc[sentence, 'Ratio'] = computeSentenceRatio(dataset.loc[sentence, 'Tag'])\n",
    "  return dataset\n",
    "      # print(dataset.loc[0, 'Tag'][tag])\n",
    "      # print(dataset.loc[0, 'Tag_idx'][tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "F8vxJiFShgCp"
   },
   "outputs": [],
   "source": [
    "dataset_untuk_sample = dataset_group.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Nc5VCwDLhUUj"
   },
   "outputs": [],
   "source": [
    "dataset_sampled = nerOversample(dataset_untuk_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "JYVER4gWh8VZ",
    "outputId": "2d4ec3d5-2bf4-4e6c-a6bc-c40bfacea0fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, I-geo, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, I-geo, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[Western, U.N., relief, coordinator, Jan, Fred...</td>\n",
       "      <td>[B-geo, I-geo, O, O, B-per, I-per, I-per, O, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47954</th>\n",
       "      <td>Sentence: 9995</td>\n",
       "      <td>[Opposition, leader, Mir, Hossein, Mason, Mous...</td>\n",
       "      <td>[O, O, O, B-per, I-per, I-per, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47955</th>\n",
       "      <td>Sentence: 9996</td>\n",
       "      <td>[On, Thursday, ,, Iranian, state, media, publi...</td>\n",
       "      <td>[O, B-tim, O, B-gpe, O, O, O, O, O, O, O, O, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47956</th>\n",
       "      <td>Sentence: 9997</td>\n",
       "      <td>[Following, Southern, Iran, 's, disputed, June...</td>\n",
       "      <td>[O, B-geo, I-geo, O, O, B-tim, I-tim, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47957</th>\n",
       "      <td>Sentence: 9998</td>\n",
       "      <td>[Since, then, ,, authorities, have, held, publ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47958</th>\n",
       "      <td>Sentence: 9999</td>\n",
       "      <td>[The, United, Community, Nations, is, praising...</td>\n",
       "      <td>[O, B-org, I-org, I-org, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47959 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence #                                               Word  \\\n",
       "0          Sentence: 1  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1         Sentence: 10  [Iranian, officials, say, they, expect, to, ge...   \n",
       "2        Sentence: 100  [Helicopter, gunships, Saturday, pounded, mili...   \n",
       "3       Sentence: 1000  [They, left, after, a, tense, hour-long, stand...   \n",
       "4      Sentence: 10000  [Western, U.N., relief, coordinator, Jan, Fred...   \n",
       "...                ...                                                ...   \n",
       "47954   Sentence: 9995  [Opposition, leader, Mir, Hossein, Mason, Mous...   \n",
       "47955   Sentence: 9996  [On, Thursday, ,, Iranian, state, media, publi...   \n",
       "47956   Sentence: 9997  [Following, Southern, Iran, 's, disputed, June...   \n",
       "47957   Sentence: 9998  [Since, then, ,, authorities, have, held, publ...   \n",
       "47958   Sentence: 9999  [The, United, Community, Nations, is, praising...   \n",
       "\n",
       "                                                     Tag  \n",
       "0      [O, O, O, O, O, O, B-geo, I-geo, O, O, O, O, O...  \n",
       "1      [B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...  \n",
       "2      [O, O, B-tim, O, O, O, O, O, B-geo, I-geo, O, ...  \n",
       "3                      [O, O, O, O, O, O, O, O, O, O, O]  \n",
       "4      [B-geo, I-geo, O, O, B-per, I-per, I-per, O, B...  \n",
       "...                                                  ...  \n",
       "47954  [O, O, O, B-per, I-per, I-per, O, O, O, O, O, ...  \n",
       "47955  [O, B-tim, O, B-gpe, O, O, O, O, O, O, O, O, B...  \n",
       "47956  [O, B-geo, I-geo, O, O, B-tim, I-tim, O, O, O,...  \n",
       "47957  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "47958  [O, B-org, I-org, I-org, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[47959 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAu2NzfIlRtg"
   },
   "outputs": [],
   "source": [
    "word_list = []\n",
    "tag_list = []\n",
    "sentence_list = []\n",
    "for sentence in range(0, dataset_sampled.shape[0]):\n",
    "  sentence_array = [dataset_sampled.loc[sentence, 'Sentence #']] * len(dataset_sampled.loc[sentence, 'Word'])\n",
    "  sentence_list = sentence_list + sentence_array\n",
    "  word_list = word_list + dataset_sampled.loc[sentence, 'Word']\n",
    "  tag_list = tag_list + dataset_sampled.loc[sentence, 'Tag']\n",
    "  # word_list.append(dataset_sampled.loc[sentence, 'Word'])\n",
    "  # tag_list = tag_list.append(dataset_sampled.loc[sentence, 'Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v77WeqBXqQnT",
    "outputId": "f12ad2dd-626d-41e8-8598-25af7e6195b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119772\n",
      "1119772\n",
      "1119772\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_list))\n",
    "print(len(word_list))\n",
    "print(len(tag_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "LlaKdqhiiRh8"
   },
   "outputs": [],
   "source": [
    "# # df_after_sampling.loc[0, \"Word\"] = dataset_sampled.\n",
    "# word = concat()\n",
    "df_after_sampling = pd.DataFrame({'Sentence #': sentence_list, 'Word': word_list, 'Tag': tag_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "yXMts75Nr3O1",
    "outputId": "90f0a020-1ef3-4082-88cc-d9c271c8487c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119767</th>\n",
       "      <td>Sentence: 9999</td>\n",
       "      <td>weight</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119768</th>\n",
       "      <td>Sentence: 9999</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119769</th>\n",
       "      <td>Sentence: 9999</td>\n",
       "      <td>gold</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119770</th>\n",
       "      <td>Sentence: 9999</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119771</th>\n",
       "      <td>Sentence: 9999</td>\n",
       "      <td>\"</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1119772 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sentence #           Word Tag\n",
       "0           Sentence: 1      Thousands   O\n",
       "1           Sentence: 1             of   O\n",
       "2           Sentence: 1  demonstrators   O\n",
       "3           Sentence: 1           have   O\n",
       "4           Sentence: 1        marched   O\n",
       "...                 ...            ...  ..\n",
       "1119767  Sentence: 9999         weight   O\n",
       "1119768  Sentence: 9999             in   O\n",
       "1119769  Sentence: 9999           gold   O\n",
       "1119770  Sentence: 9999              .   O\n",
       "1119771  Sentence: 9999              \"   O\n",
       "\n",
       "[1119772 rows x 3 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GmVX7l8kr_bL",
    "outputId": "826d452d-d6f8-4634-8b7a-b8610e43a394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8294344960839113\n"
     ]
    }
   ],
   "source": [
    "print(computeRatioAwal(df_after_sampling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AIb7Qz73_ubI",
    "outputId": "562a5d92-5e6e-4d19-eb80-594aa90bf7ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        887908\n",
       "I-geo     42247\n",
       "B-geo     37644\n",
       "I-org     36388\n",
       "I-per     34011\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "B-per     16990\n",
       "B-gpe     15870\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_sampling[\"Tag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "ADiFtpkoIicd"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def get_dict_map(dataset, token_or_tag):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set(dataset['Word'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(dataset['Tag'].to_list()))\n",
    "    \n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "    return tok2idx, idx2tok\n",
    "token2idx, idx2token = get_dict_map(df_after_sampling, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(df_after_sampling, 'tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYC3TQaDLz4d",
    "outputId": "6a1f5a2a-d21b-4b63-a233-14c7739ceb9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-gpe': 0, 'B-org': 1, 'B-art': 2, 'I-art': 3, 'I-org': 4, 'B-gpe': 5, 'B-per': 6, 'I-geo': 7, 'I-per': 8, 'B-geo': 9, 'I-tim': 10, 'O': 11, 'B-nat': 12, 'I-nat': 13, 'B-tim': 14, 'B-eve': 15, 'I-eve': 16}\n"
     ]
    }
   ],
   "source": [
    "print(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzVHRVQXMaNE",
    "outputId": "c03e53dd-8b2c-4230-9c9f-dc5aee5f3b06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(tag2idx.get('B-geo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cco1WLsXIpmz",
    "outputId": "c9b6285c-0a1e-4f59-c96b-dba02919c6e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df_after_sampling['Word_idx'] = df_after_sampling['Word'].map(token2idx)\n",
    "df_after_sampling['Tag_idx'] = df_after_sampling['Tag'].map(tag2idx)\n",
    "df_after_sampling_fillna = df_after_sampling.fillna(method='ffill', axis=0)\n",
    "# Groupby and collect columns\n",
    "df_after_sampling_group = df_after_sampling_fillna.groupby(['Sentence #'], as_index=False)['Word', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "ZvTPg33qybAX",
    "outputId": "eface04f-a42b-444b-ad61-a351bac9d33b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, I-geo, O, O, O, O, O...</td>\n",
       "      <td>[16508, 17088, 15567, 14065, 17944, 31862, 321...</td>\n",
       "      <td>[11, 11, 11, 11, 11, 11, 9, 7, 11, 11, 11, 11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[24030, 33814, 24773, 17546, 26595, 31640, 267...</td>\n",
       "      <td>[5, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, I-geo, O, ...</td>\n",
       "      <td>[24167, 3723, 32397, 15242, 22124, 18508, 1234...</td>\n",
       "      <td>[11, 11, 14, 11, 11, 11, 11, 11, 9, 7, 11, 11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[1383, 24471, 21163, 24287, 26087, 17869, 3138...</td>\n",
       "      <td>[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[Eastern, U.N., relief, coordinator, Jan, Wood...</td>\n",
       "      <td>[B-geo, I-geo, O, O, B-per, I-per, I-per, O, B...</td>\n",
       "      <td>[14122, 10459, 3346, 6497, 33092, 25671, 12070...</td>\n",
       "      <td>[9, 7, 11, 11, 6, 8, 8, 11, 14, 11, 9, 7, 11, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47954</th>\n",
       "      <td>Sentence: 9995</td>\n",
       "      <td>[Opposition, leader, Mir, Hossein, Christopher...</td>\n",
       "      <td>[O, O, O, B-per, I-per, I-per, O, O, O, O, O, ...</td>\n",
       "      <td>[17308, 1592, 4838, 19176, 28074, 15907, 30875...</td>\n",
       "      <td>[11, 11, 11, 6, 8, 8, 11, 11, 11, 11, 11, 11, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47955</th>\n",
       "      <td>Sentence: 9996</td>\n",
       "      <td>[On, Thursday, ,, Iranian, state, media, publi...</td>\n",
       "      <td>[O, B-tim, O, B-gpe, O, O, O, O, O, O, O, O, B...</td>\n",
       "      <td>[28775, 21190, 29169, 24030, 12882, 27779, 268...</td>\n",
       "      <td>[11, 14, 11, 5, 11, 11, 11, 11, 11, 11, 11, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47956</th>\n",
       "      <td>Sentence: 9997</td>\n",
       "      <td>[Following, Western, Iran, 's, disputed, June,...</td>\n",
       "      <td>[O, B-geo, I-geo, O, O, B-tim, I-tim, O, O, O,...</td>\n",
       "      <td>[17098, 14006, 800, 33156, 8549, 13026, 17256,...</td>\n",
       "      <td>[11, 9, 7, 11, 11, 14, 10, 11, 11, 11, 11, 11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47957</th>\n",
       "      <td>Sentence: 9998</td>\n",
       "      <td>[Since, then, ,, authorities, have, held, publ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[26476, 18352, 29169, 24054, 14065, 35030, 333...</td>\n",
       "      <td>[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47958</th>\n",
       "      <td>Sentence: 9999</td>\n",
       "      <td>[The, United, Community, Nations, is, praising...</td>\n",
       "      <td>[O, B-org, I-org, I-org, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[9639, 21874, 22876, 10600, 20987, 16002, 1212...</td>\n",
       "      <td>[11, 1, 4, 4, 11, 11, 11, 11, 11, 11, 11, 11, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47959 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence #  ...                                            Tag_idx\n",
       "0          Sentence: 1  ...  [11, 11, 11, 11, 11, 11, 9, 7, 11, 11, 11, 11,...\n",
       "1         Sentence: 10  ...  [5, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11...\n",
       "2        Sentence: 100  ...  [11, 11, 14, 11, 11, 11, 11, 11, 9, 7, 11, 11,...\n",
       "3       Sentence: 1000  ...       [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
       "4      Sentence: 10000  ...  [9, 7, 11, 11, 6, 8, 8, 11, 14, 11, 9, 7, 11, ...\n",
       "...                ...  ...                                                ...\n",
       "47954   Sentence: 9995  ...  [11, 11, 11, 6, 8, 8, 11, 11, 11, 11, 11, 11, ...\n",
       "47955   Sentence: 9996  ...  [11, 14, 11, 5, 11, 11, 11, 11, 11, 11, 11, 11...\n",
       "47956   Sentence: 9997  ...  [11, 9, 7, 11, 11, 14, 10, 11, 11, 11, 11, 11,...\n",
       "47957   Sentence: 9998  ...  [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1...\n",
       "47958   Sentence: 9999  ...  [11, 1, 4, 4, 11, 11, 11, 11, 11, 11, 11, 11, ...\n",
       "\n",
       "[47959 rows x 5 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_sampling_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cDQdPx8FzJXV"
   },
   "outputs": [],
   "source": [
    "def countEntity(tags):\n",
    "  positive_tag = 0\n",
    "  negative_tag = 0\n",
    "  for tag in tags:\n",
    "    # print(tag)\n",
    "    if (tag == \"O\"):\n",
    "      negative_tag += 1\n",
    "    else:\n",
    "      positive_tag += 1\n",
    "  return positive_tag, negative_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qiYsmQuUxsJd"
   },
   "outputs": [],
   "source": [
    "def computeInitialRatio(dataset):\n",
    "  for sentence in range(0, dataset.shape[0]):\n",
    "    # print (sentence)\n",
    "    # print(dataset.loc[sentence][\"Word\"])\n",
    "    positive_sample, negative_sample = countEntity(dataset.loc[sentence][\"Tag\"])\n",
    "    # print(positive_sample, negative_sample)\n",
    "    \n",
    "    \n",
    "    if(positive_sample == 0):\n",
    "      # dataset.loc[sentence][\"Ratio\"] = dataset.loc[sentence][\"Ratio\"].replace([dataset.loc[sentence][\"Ratio\"]], negative_sample)\n",
    "      dataset.loc[sentence, \"Ratio\"] = negative_sample\n",
    "      # print(dataset.loc[sentence][\"Ratio\"])\n",
    "      # print('no positive sample')\n",
    "    else:\n",
    "      ratio = negative_sample / positive_sample\n",
    "      # print(ratio)\n",
    "      dataset.loc[sentence, \"Ratio\"] = ratio\n",
    "      # dataset.loc[sentence, \"Ratio\"] = dataset.loc[sentence][\"Ratio\"].replace([dataset.loc[sentence][\"Ratio\"]], ratio)\n",
    "      # print(dataset.loc[sentence, \"Ratio\"])\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pRjPcdJDRedx"
   },
   "outputs": [],
   "source": [
    "def computeSentenceRatio(tags):\n",
    "  positive_sample, negative_sample = countEntity(tags)\n",
    "  if(positive_sample == 0):\n",
    "    return negative_sample\n",
    "  else:\n",
    "    return negative_sample / positive_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Lbv8AdbH0Sb7"
   },
   "outputs": [],
   "source": [
    "dataset_baru = computeInitialRatio(dataset_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "QEl3tymIoZjJ",
    "outputId": "20736644-5a05-4957-ac3e-5c958de681e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "      <th>Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "      <td>[16509, 17089, 15568, 14066, 17945, 31861, 302...</td>\n",
       "      <td>[12, 12, 12, 12, 12, 12, 10, 12, 12, 12, 12, 1...</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[24032, 33813, 24774, 17547, 26596, 31639, 267...</td>\n",
       "      <td>[6, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12...</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
       "      <td>[24169, 3724, 32396, 15243, 22126, 18509, 1234...</td>\n",
       "      <td>[12, 12, 15, 12, 12, 12, 12, 12, 10, 12, 12, 1...</td>\n",
       "      <td>5.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[1383, 24472, 21165, 24289, 26088, 17870, 3138...</td>\n",
       "      <td>[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
       "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...</td>\n",
       "      <td>[10460, 3347, 6498, 33091, 12071, 13775, 19369...</td>\n",
       "      <td>[10, 12, 12, 7, 9, 12, 15, 12, 10, 12, 6, 12, ...</td>\n",
       "      <td>3.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47954</th>\n",
       "      <td>Sentence: 9995</td>\n",
       "      <td>[Opposition, leader, Mir, Hossein, Mousavi, ha...</td>\n",
       "      <td>[O, O, O, B-per, I-per, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[17309, 1592, 4839, 19177, 15908, 30874, 13775...</td>\n",
       "      <td>[12, 12, 12, 7, 9, 12, 12, 12, 12, 12, 12, 12,...</td>\n",
       "      <td>5.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47955</th>\n",
       "      <td>Sentence: 9996</td>\n",
       "      <td>[On, Thursday, ,, Iranian, state, media, publi...</td>\n",
       "      <td>[O, B-tim, O, B-gpe, O, O, O, O, O, O, O, O, B...</td>\n",
       "      <td>[28775, 21192, 29168, 24032, 12883, 27779, 268...</td>\n",
       "      <td>[12, 15, 12, 6, 12, 12, 12, 12, 12, 12, 12, 12...</td>\n",
       "      <td>5.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47956</th>\n",
       "      <td>Sentence: 9997</td>\n",
       "      <td>[Following, Iran, 's, disputed, June, 12, elec...</td>\n",
       "      <td>[O, B-geo, O, O, B-tim, I-tim, O, O, O, O, O, ...</td>\n",
       "      <td>[17099, 800, 33155, 8551, 13027, 17257, 27077,...</td>\n",
       "      <td>[12, 10, 12, 12, 15, 11, 12, 12, 12, 12, 12, 1...</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47957</th>\n",
       "      <td>Sentence: 9998</td>\n",
       "      <td>[Since, then, ,, authorities, have, held, publ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[26477, 18353, 29168, 24056, 14066, 35029, 333...</td>\n",
       "      <td>[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47958</th>\n",
       "      <td>Sentence: 9999</td>\n",
       "      <td>[The, United, Nations, is, praising, the, use,...</td>\n",
       "      <td>[O, B-org, I-org, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[9640, 21876, 10601, 20989, 16003, 12123, 2847...</td>\n",
       "      <td>[12, 1, 4, 12, 12, 12, 12, 12, 12, 12, 12, 12,...</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47959 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence #  ...      Ratio\n",
       "0          Sentence: 1  ...   7.000000\n",
       "1         Sentence: 10  ...   7.333333\n",
       "2        Sentence: 100  ...   5.400000\n",
       "3       Sentence: 1000  ...  11.000000\n",
       "4      Sentence: 10000  ...   3.375000\n",
       "...                ...  ...        ...\n",
       "47954   Sentence: 9995  ...   5.400000\n",
       "47955   Sentence: 9996  ...   5.250000\n",
       "47956   Sentence: 9997  ...   8.000000\n",
       "47957   Sentence: 9998  ...  21.000000\n",
       "47958   Sentence: 9999  ...   7.000000\n",
       "\n",
       "[47959 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgVnMjx8Exaa",
    "outputId": "cddd21bf-7d33-4ed8-afef-b86ffb80e3cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    47959.000000\n",
       "mean         8.753518\n",
       "std          7.186852\n",
       "min          0.000000\n",
       "25%          3.600000\n",
       "50%          6.250000\n",
       "75%         12.000000\n",
       "max         80.000000\n",
       "Name: Ratio, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_baru['Ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ddqIMVAoT2rw"
   },
   "outputs": [],
   "source": [
    "dataset_backup = dataset_baru.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sqvN3aZWW8wN"
   },
   "outputs": [],
   "source": [
    "dataset_untuk_sample = dataset_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "rEw_5TIIX9vD"
   },
   "outputs": [],
   "source": [
    "dataset_baseline = dataset_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "pYm7bm-qHpI6"
   },
   "outputs": [],
   "source": [
    "dataset_sampled = nerOversample(dataset_untuk_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "Cp_6AbBzXOHs",
    "outputId": "40a253dd-8177-4ee1-9e8b-3e93c2d4f252"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "      <th>Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, I-geo, O, O, O, O, O...</td>\n",
       "      <td>[16509, 17089, 15568, 14066, 17945, 31861, 302...</td>\n",
       "      <td>[12, 12, 12, 12, 12, 12, 10, 8, 12, 12, 12, 12...</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[24032, 33813, 24774, 17547, 26596, 31639, 267...</td>\n",
       "      <td>[6, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12...</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, I-geo, O, ...</td>\n",
       "      <td>[24169, 3724, 32396, 15243, 22126, 18509, 1234...</td>\n",
       "      <td>[12, 12, 15, 12, 12, 12, 12, 12, 10, 8, 12, 12...</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[1383, 24472, 21165, 24289, 26088, 17870, 3138...</td>\n",
       "      <td>[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[Eastern, U.N., relief, coordinator, Jan, Wood...</td>\n",
       "      <td>[B-geo, I-geo, O, O, B-per, I-per, I-per, O, B...</td>\n",
       "      <td>[10460, 3347, 6498, 33091, 12071, 13775, 19369...</td>\n",
       "      <td>[10, 8, 12, 12, 7, 9, 9, 12, 15, 12, 10, 8, 12...</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47954</th>\n",
       "      <td>Sentence: 9995</td>\n",
       "      <td>[Opposition, leader, Mir, Hossein, Mason, Mous...</td>\n",
       "      <td>[O, O, O, B-per, I-per, I-per, O, O, O, O, O, ...</td>\n",
       "      <td>[17309, 1592, 4839, 19177, 15908, 30874, 13775...</td>\n",
       "      <td>[12, 12, 12, 7, 9, 9, 12, 12, 12, 12, 12, 12, ...</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47955</th>\n",
       "      <td>Sentence: 9996</td>\n",
       "      <td>[On, Thursday, ,, Iranian, state, media, publi...</td>\n",
       "      <td>[O, B-tim, O, B-gpe, O, O, O, O, O, O, O, O, B...</td>\n",
       "      <td>[28775, 21192, 29168, 24032, 12883, 27779, 268...</td>\n",
       "      <td>[12, 15, 12, 6, 12, 12, 12, 12, 12, 12, 12, 12...</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47956</th>\n",
       "      <td>Sentence: 9997</td>\n",
       "      <td>[Following, Western, Iran, 's, disputed, June,...</td>\n",
       "      <td>[O, B-geo, I-geo, O, O, B-tim, I-tim, O, O, O,...</td>\n",
       "      <td>[17099, 800, 33155, 8551, 13027, 17257, 27077,...</td>\n",
       "      <td>[12, 10, 8, 12, 12, 15, 11, 12, 12, 12, 12, 12...</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47957</th>\n",
       "      <td>Sentence: 9998</td>\n",
       "      <td>[Since, then, ,, authorities, have, held, publ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[26477, 18353, 29168, 24056, 14066, 35029, 333...</td>\n",
       "      <td>[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47958</th>\n",
       "      <td>Sentence: 9999</td>\n",
       "      <td>[The, United, Community, Nations, is, praising...</td>\n",
       "      <td>[O, B-org, I-org, I-org, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[9640, 21876, 10601, 20989, 16003, 12123, 2847...</td>\n",
       "      <td>[12, 1, 4, 4, 12, 12, 12, 12, 12, 12, 12, 12, ...</td>\n",
       "      <td>5.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47959 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence #  ...      Ratio\n",
       "0          Sentence: 1  ...   4.200000\n",
       "1         Sentence: 10  ...   5.500000\n",
       "2        Sentence: 100  ...   3.857143\n",
       "3       Sentence: 1000  ...  11.000000\n",
       "4      Sentence: 10000  ...   2.250000\n",
       "...                ...  ...        ...\n",
       "47954   Sentence: 9995  ...   3.857143\n",
       "47955   Sentence: 9996  ...   4.200000\n",
       "47956   Sentence: 9997  ...   6.000000\n",
       "47957   Sentence: 9998  ...  21.000000\n",
       "47958   Sentence: 9999  ...   5.600000\n",
       "\n",
       "[47959 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqqKa80FXsW5",
    "outputId": "140592bb-a5b7-4c32-9c91-c5a9dd27c338"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    47959.000000\n",
       "mean         6.814411\n",
       "std          6.632256\n",
       "min          0.000000\n",
       "25%          2.500000\n",
       "50%          4.200000\n",
       "75%          9.000000\n",
       "max         70.000000\n",
       "Name: Ratio, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sampled['Ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "0-6DeB4DI0dq"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def get_pad_train_test_val(dataset_grouped, dataset):\n",
    "\n",
    "    #get max token and tag length\n",
    "    n_token = len(list(set(dataset['Word'].to_list())))\n",
    "    n_tag = len(list(set(dataset['Tag'].to_list())))\n",
    "\n",
    "    #Pad tokens (X var)    \n",
    "    tokens = dataset_grouped['Word_idx'].tolist()\n",
    "    maxlen = max([len(s) for s in tokens])\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n",
    "\n",
    "    #Pad Tags (y var) and convert it into one hot encoding\n",
    "    tags = dataset_grouped['Tag_idx'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n",
    "    n_tags = len(tag2idx)\n",
    "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
    "    \n",
    "    #Split train, test and validation set\n",
    "    tokens_, test_tokens, tags_, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
    "    train_tokens, val_tokens, train_tags, val_tags = train_test_split(tokens_,tags_,test_size = 0.25,train_size =0.75, random_state=2020)\n",
    "\n",
    "    print(\n",
    "        'train_tokens length:', len(train_tokens),\n",
    "        '\\ntrain_tags length:', len(train_tags),\n",
    "        '\\ntest_tokens length:', len(test_tokens),\n",
    "        '\\ntest_tags:', len(test_tags),\n",
    "        '\\nval_tokens:', len(val_tokens),\n",
    "        '\\nval_tags:', len(val_tags),\n",
    "    )\n",
    "    \n",
    "    return train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zfgcg9yYwc-",
    "outputId": "48562b55-e5d6-47a0-e37d-4818f39b1aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tokens length: 32372 \n",
      "train_tags length: 32372 \n",
      "test_tokens length: 4796 \n",
      "test_tags: 4796 \n",
      "val_tokens: 10791 \n",
      "val_tags: 10791\n",
      "train_tags:  (32372, 109, 17) val_tags:  (10791, 109, 17) test_tags:  (4796, 109, 17)\n"
     ]
    }
   ],
   "source": [
    "train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags = get_pad_train_test_val(df_after_sampling_group, df_after_sampling)\n",
    "train_tags = np.array(train_tags)\n",
    "val_tags = np.array(val_tags)\n",
    "test_tags = np.array(test_tags)\n",
    "print('train_tags: ',train_tags.shape,'val_tags: ',val_tags.shape,'test_tags: ',test_tags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cuPnEznJI_sm",
    "outputId": "11638375-b47d-4abf-a8d7-e885f1c93c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "train_temp_tags = np.ravel(np.argmax(train_tags, axis=-1))\n",
    "print(len(train_temp_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rolnqkh7GL8P",
    "outputId": "07446318-288e-4d60-f4d9-7f2396e860f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1647.3146591970121, 1: 15.296753412839822, 2: 736.0342094284522, 3: 1002.7132708155726, 4: 8.414547657146128, 5: 19.418247456153384, 6: 18.21674978574895, 7: 7.281587337618787, 8: 9.08207084356452, 9: 8.191713910285877, 10: 47.2805574165885, 11: 0.06154951575920901, 12: 1526.188581314879, 13: 6486.301470588235, 14: 15.149379392659188, 15: 1022.4711677774558, 16: 1128.0524296675192}\n",
      "(32372, 109)\n",
      "(32372, 109)\n"
     ]
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight ='balanced', \n",
    "    classes = np.unique(train_temp_tags), \n",
    "    y = train_temp_tags\n",
    "    )\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(class_weight_dict)\n",
    "\n",
    "train_label = np.argmax(train_tags, axis=-1)\n",
    "print(train_tokens.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "nGvi5V0oJJxt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "Jyq_gb1sJNQB"
   },
   "outputs": [],
   "source": [
    "input_dim = len(list(set(df_after_sampling['Word'].to_list())))+1\n",
    "output_dim = 64\n",
    "input_length = max([len(s) for s in df_after_sampling_group['Word_idx'].tolist()])\n",
    "n_tags = len(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "YD-esmi8JTid"
   },
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add((Dense(n_tags, activation=\"softmax\")))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPGriHINJWsx",
    "outputId": "5a8ee827-7c1d-4294-c267-05b0f141c556"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1647.3146591970121, 1: 15.296753412839822, 2: 736.0342094284522, 3: 1002.7132708155726, 4: 8.414547657146128, 5: 19.418247456153384, 6: 18.21674978574895, 7: 7.281587337618787, 8: 9.08207084356452, 9: 8.191713910285877, 10: 47.2805574165885, 11: 28.52779541057316, 12: 1526.188581314879, 13: 6486.301470588235, 14: 15.149379392659188, 15: 1022.4711677774558, 16: 1128.0524296675192}\n",
      "(32372, 109)\n"
     ]
    }
   ],
   "source": [
    "maj_index = tag2idx['O']\n",
    "\n",
    "''' Change it More for Better Fine-Tuning '''\n",
    "\n",
    "class_weight_dict[maj_index] = 28.5277954105731576 \n",
    "print(class_weight_dict)\n",
    "sample_weights = np.ones(shape=(len(train_label), train_label.shape[-1]))\n",
    "for i in range(17):\n",
    "    sample_weights[train_label == i] = class_weight_dict.get(i)\n",
    "print(sample_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iv558V4rJb7i",
    "outputId": "ad8f17eb-0d82-4df9-e97c-edbebeb68a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 109, 64)           2251072   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 109, 128)         66048     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 109, 64)           49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 109, 17)           1105      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,367,633\n",
      "Trainable params: 2,367,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "405/405 [==============================] - 305s 732ms/step - loss: 6.8836 - accuracy: 0.9532 - val_loss: 3.3816 - val_accuracy: 0.9561\n",
      "Epoch 2/5\n",
      "405/405 [==============================] - 295s 729ms/step - loss: 3.1061 - accuracy: 0.9624 - val_loss: 2.5941 - val_accuracy: 0.9733\n",
      "Epoch 3/5\n",
      "405/405 [==============================] - 294s 725ms/step - loss: 2.4795 - accuracy: 0.9729 - val_loss: 2.1668 - val_accuracy: 0.9760\n",
      "Epoch 4/5\n",
      "405/405 [==============================] - 292s 722ms/step - loss: 1.8806 - accuracy: 0.9801 - val_loss: 1.7647 - val_accuracy: 0.9842\n",
      "Epoch 5/5\n",
      "405/405 [==============================] - 300s 740ms/step - loss: 1.4580 - accuracy: 0.9856 - val_loss: 1.6013 - val_accuracy: 0.9870\n"
     ]
    }
   ],
   "source": [
    "nlp_model = get_bilstm_lstm_model()\n",
    "plot_model(nlp_model)\n",
    "his = nlp_model.fit(train_tokens, train_label , batch_size = 64, epochs=5, validation_split=0.2, sample_weight = sample_weights) \n",
    "tf.keras.models.save_model(nlp_model, filepath  = \"/content/drive/MyDrive/Colab Notebooks/ner-kk/rnn_model_sampled_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "id": "DgZUHDk3Jr7t",
    "outputId": "a7a62fc6-b7ed-419f-e55e-55b0799dad2f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-82ab717f400d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/ner-kk/rnn_model_sampled_2.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "nlp_model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/ner-kk/rnn_model_sampled_2.h5')\n",
    "\n",
    "y_test = np.argmax(test_tags, axis=-1)\n",
    "print(test_tokens.shape,y_test.shape)\n",
    "nlp_model.evaluate(test_tokens, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM5w1shLf9zN/Wbur+kg9ni",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "FP-KK-NER-RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
